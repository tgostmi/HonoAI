import re
import asyncio
import random
import time

chat_model_index = 0
chat_model_lock = asyncio.Lock()
_skip_cache = {}
_last_ai_call = {}
AI_COOLDOWN = 3


def _should_skip_fast(text: str, context: list, my_username: str) -> tuple:
    text_lower = text.lower().strip()
    
    if len(text_lower) < 3:
        return (True, "too_short")
    
    skip_patterns = [
        r'^\.+$', r'^\?+$', r'^!+$', r'^[–∞-—èa-z]{1,2}$',
        r'^(–æ–∫|–æ–∫–µ–π|–¥–∞|–Ω–µ—Ç|–Ω–æ—Ä–º|—Ö–∑|–Ω—É|–∞–≥–∞|—É–≥—É|–ª–∞–Ω|—è—Å–Ω–æ|–ø–æ–Ω—è–ª|–∫–µ–∫|–ª–æ–ª|—Ö–∞—Ö|–∞—Ö–∞—Ö)$',
        r'^[üòÇü§£üò≠üíÄüòéüî•üëçüëé‚ù§Ô∏è]+$',
    ]
    for pattern in skip_patterns:
        if re.match(pattern, text_lower):
            return (True, "trivial")
    
    if context and my_username:
        my_count = sum(1 for m in context[-8:] if (m.get('username') or '').lower() == my_username.lower())
        if my_count >= 3:
            return (True, "spam_protection")
    
    return (False, None)


def should_respond_quick(text: str, my_username: str, my_id: int, reply_to_me: bool, mentioned_ids: list = None) -> tuple:
    text_lower = text.lower()
    
    if reply_to_me:
        return (True, "reply")
    
    if mentioned_ids and my_id in mentioned_ids:
        return (True, "mention_id")
    
    if my_username:
        if f"@{my_username.lower()}" in text_lower:
            return (True, "mention_username")
    
    name_patterns = [r'\b—Ö–æ–Ω–æ\b', r'\b—Ö–æ–Ω–æ—á–∫–∞\b', r'\bhono\b']
    for pattern in name_patterns:
        if re.search(pattern, text_lower):
            return (True, "mention_name")
    
    return (None, None)


async def should_respond_ai(ai_client, models: list, text: str, context: list, my_username: str, sender_username: str = None, chat_id: int = 0) -> tuple:
    global chat_model_index, _skip_cache, _last_ai_call
    
    if not models or not ai_client:
        return (False, None)
    
    if sender_username and sender_username.lower() == my_username.lower():
        return (False, "self_message")
    
    skip, reason = _should_skip_fast(text, context, my_username)
    if skip:
        return (False, reason)
    
    now = time.time()
    if chat_id:
        last_call = _last_ai_call.get(chat_id, 0)
        if now - last_call < AI_COOLDOWN:
            return (False, "cooldown")
        _last_ai_call[chat_id] = now
        
        cache_key = f"{chat_id}_{hash(text[:50])}"
        cached = _skip_cache.get(cache_key)
        if cached and now - cached < 60:
            return (False, "cached_skip")
    
    async with chat_model_lock:
        model = models[chat_model_index % len(models)]
        chat_model_index += 1
    
    context_lines = []
    hono_spoke_last = False
    hono_was_in_chat = False
    last_hono_idx = -1
    
    if context:
        recent = context[-12:]
        for i, m in enumerate(recent):
            username = m.get('username')
            if not username or username == 'None':
                username = f"user_{m.get('user_id', '?')}"
            username = str(username)
            msg = m.get('message', '').replace('\n', ' ')[:100]
            is_hono = username and my_username and username.lower() == my_username.lower()
            if is_hono:
                context_lines.append(f"[–Ø]: {msg}")
                hono_was_in_chat = True
                last_hono_idx = i
                if i == len(recent) - 1:
                    hono_spoke_last = True
            else:
                context_lines.append(f"[{username}]: {msg}")
    
    context_text = "\n".join(context_lines)
    clean_text = text.replace('\n', ' ')[:150]
    
    hono_count = sum(1 for line in context_lines if line.startswith("[–Ø]:"))
    recent_5 = context_lines[-5:] if len(context_lines) >= 5 else context_lines
    hono_in_recent = sum(1 for line in recent_5 if line.startswith("[–Ø]:"))
    
    if hono_in_recent >= 2:
        print(f"[CHAT AI] –ú–Ω–æ–≥–æ –º–æ–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π ({hono_in_recent}/5), –º–æ–ª—á—É")
        return (False, "spam_prevention")
    
    msgs_after_hono = len(context_lines) - last_hono_idx - 1 if last_hono_idx >= 0 else 999
    
    system_prompt = """–¢—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –Ω—É–∂–Ω–æ –ª–∏ –æ—Ç–≤–µ—á–∞—Ç—å. [–Ø] = —Ç–≤–æ–∏ —Å–æ–æ–±—â–µ–Ω–∏—è.
–û—Ç–≤–µ—á–∞–π –°–¢–†–û–ì–û: –¥–∞ –∏–ª–∏ –Ω–µ—Ç"""

    prompt = f"""–ö–û–ù–¢–ï–ö–°–¢ –ß–ê–¢–ê:
{context_text}

–ù–û–í–û–ï –°–û–û–ë–©–ï–ù–ò–ï –æ—Ç {sender_username or 'user'}: "{clean_text}"

–û–¢–í–ï–ß–ê–Æ –¢–û–õ–¨–ö–û –ï–°–õ–ò:
- –ú–µ–Ω—è –ù–ê–ü–†–Ø–ú–£–Æ –∑–æ–≤—É—Ç –ø–æ –∏–º–µ–Ω–∏ (–•–æ–Ω–æ/Hono) –∏–ª–∏ —Ç–µ–≥–∞—é—Ç
- –í–æ–ø—Ä–æ—Å/–ø—Ä–æ—Å—å–±–∞ –ê–î–†–ï–°–û–í–ê–ù–´ –ú–ù–ï –ª–∏—á–Ω–æ
- –û—Ç–≤–µ—á–∞—é—Ç –ù–ê–ü–†–Ø–ú–£–Æ –Ω–∞ –º–æ—ë —Å–æ–æ–±—â–µ–Ω–∏–µ –∏ –∂–¥—É—Ç –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è

–ù–ï –û–¢–í–ï–ß–ê–Æ:
- –õ—é–¥–∏ –æ–±—â–∞—é—Ç—Å—è –º–µ–∂–¥—É —Å–æ–±–æ–π (–¥–∞–∂–µ –µ—Å–ª–∏ –∑–∞–¥–∞—é—Ç –≤–æ–ø—Ä–æ—Å—ã –¥—Ä—É–≥ –¥—Ä—É–≥—É)
- –û–±—Å—É–∂–¥–µ–Ω–∏–µ –≥–¥–µ —è –Ω–µ —É—á–∞—Å—Ç–Ω–∏–∫
- –ú–µ–Ω—è –Ω–µ –∑–≤–∞–ª–∏ –∏ –Ω–µ —Å–ø—Ä–∞—à–∏–≤–∞–ª–∏

–≠—Ç–æ –æ–±—ã—á–Ω—ã–π —á–∞—Ç. –ï—Å–ª–∏ –º–µ–Ω—è –Ω–µ –ø–æ–∑–≤–∞–ª–∏ - —è –º–æ–ª—á—É.

–û–¢–í–ï–¢ (–¥–∞/–Ω–µ—Ç):"""

    print(f"[CHAT AI] –ö–æ–Ω—Ç–µ–∫—Å—Ç ({len(context)} —Å–æ–æ–±—â.):")
    for line in context_text.split('\n')[-6:]:
        print(f"  {line[:120]}")
    print(f"[CHAT AI] –°–æ–æ–±—â–µ–Ω–∏–µ: {clean_text[:150]}")
    
    response = ""
    attempt = 0
    max_attempts = 50
    current_model_idx = chat_model_index - 1
    
    while attempt < max_attempts:
        current_model = models[current_model_idx % len(models)]
        print(f"[CHAT AI] –ú–æ–¥–µ–ª—å: {current_model}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}")
        
        try:
            result = await ai_client.chat(current_model, [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ], retries=1, max_tokens=50)
            
            print(f"[CHAT AI] RAW —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {repr(result)[:200]}")
            
            if isinstance(result, dict):
                response = result.get("content", "")
                if not response:
                    print(f"[CHAT AI] –û–®–ò–ë–ö–ê: content –ø—É—Å—Ç–æ–π –≤ dict!")
                    attempt += 1
                    current_model_idx += 1
                    await asyncio.sleep(1)
                    continue
                response = response.lower().strip()
            else:
                response = str(result).lower().strip()
            
            if "prohibited_content" in response or "prohibited content" in response:
                print(f"[CHAT AI] PROHIBITED_CONTENT, –ø—Ä–æ–ø—É—Å–∫–∞—é —Å–æ–æ–±—â–µ–Ω–∏–µ")
                return (False, "prohibited")
            
            if "rate limit" in response or "–æ—à–∏–±–∫–∞" in response or "error" in response:
                print(f"[CHAT AI] Rate limit –≤ –æ—Ç–≤–µ—Ç–µ, –º–µ–Ω—è—é –º–æ–¥–µ–ª—å...")
                current_model_idx += 1
                await asyncio.sleep(2)
                continue
            
            if response and len(response) > 0:
                break
                
            print(f"[CHAT AI] –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç: '{response}', –º–µ–Ω—è—é –º–æ–¥–µ–ª—å...")
            attempt += 1
            current_model_idx += 1
            await asyncio.sleep(1)
                
        except Exception as e:
            error_str = str(e).lower()
            print(f"[CHAT AI] EXCEPTION: {e}")
            
            if "rate limit" in error_str:
                print(f"[CHAT AI] Rate limit exception, –∂–¥—É 3 —Å–µ–∫ –∏ –º–µ–Ω—è—é –º–æ–¥–µ–ª—å...")
                current_model_idx += 1
                await asyncio.sleep(3)
                continue
            
            attempt += 1
            current_model_idx += 1
            await asyncio.sleep(1)
    
    print(f"[CHAT AI] –û—Ç–≤–µ—Ç: {response}")
    
    if "–¥–∞" in response or response == "yes":
        return (True, "ai_decision")
    
    if chat_id:
        cache_key = f"{chat_id}_{hash(text[:50])}"
        _skip_cache[cache_key] = time.time()
        if len(_skip_cache) > 1000:
            old_keys = [k for k, v in _skip_cache.items() if time.time() - v > 300]
            for k in old_keys:
                _skip_cache.pop(k, None)
    
    return (False, "ai_skip")


def get_group_system_prompt(group_info: dict, context: list) -> str:
    prompt_parts = [
        "–¢–´ –í –ì–†–£–ü–ü–û–í–û–ú –ß–ê–¢–ï!",
        "",
        "–ü–†–ê–í–ò–õ–ê –ü–û–í–ï–î–ï–ù–ò–Ø –í –ì–†–£–ü–ü–ï:",
        "- –û—Ç–≤–µ—á–∞–π –ö–û–†–û–¢–ö–û, 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è",
        "- –ù–µ –¥–æ–º–∏–Ω–∏—Ä—É–π, –¥–∞–π –¥—Ä—É–≥–∏–º –≥–æ–≤–æ—Ä–∏—Ç—å",
        "- –ë—É–¥—å —á–∞—Å—Ç—å—é –±–µ—Å–µ–¥—ã, –Ω–µ —Ü–µ–Ω—Ç—Ä–æ–º –≤–Ω–∏–º–∞–Ω–∏—è",
        "- –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç ‚Äî —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏",
        "- –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π —Ç–æ —á—Ç–æ —É–∂–µ —Å–∫–∞–∑–∞–ª–∏ –¥—Ä—É–≥–∏–µ",
        "- –°–ª–µ–¥–∏ –∑–∞ —Ç–µ–º–æ–π —Ä–∞–∑–≥–æ–≤–æ—Ä–∞",
    ]
    
    if group_info:
        prompt_parts.append("")
        prompt_parts.append(f"–ì–†–£–ü–ü–ê: {group_info.get('title', '?')}")
        
        if group_info.get('rules'):
            prompt_parts.append(f"–ü–†–ê–í–ò–õ–ê –ß–ê–¢–ê: {group_info['rules'][:500]}")
            prompt_parts.append("–°–¢–†–û–ì–û –°–û–ë–õ–Æ–î–ê–ô –ü–†–ê–í–ò–õ–ê –ß–ê–¢–ê!")
        
        if group_info.get('staff'):
            prompt_parts.append(f"–ê–î–ú–ò–ù–´: {group_info['staff'][:200]}")
        
        if group_info.get('topics'):
            prompt_parts.append(f"–¢–ï–ú–´ –ß–ê–¢–ê: {group_info['topics']}")
    
    if context:
        prompt_parts.append("")
        prompt_parts.append("–ù–ï–î–ê–í–ù–ò–ï –°–û–û–ë–©–ï–ù–ò–Ø –í –ß–ê–¢–ï:")
        for msg in context[-10:]:
            username = msg.get('username', 'user')
            text = msg.get('message', '')[:100]
            prompt_parts.append(f"@{username}: {text}")
    
    return "\n".join(prompt_parts)


async def parse_rules_ai(ai_client, model: str, text: str) -> str:
    if not text or len(text) < 15:
        return None
    
    try:
        check_prompt = f"""–≠—Ç–æ –ø—Ä–∞–≤–∏–ª–∞ —á–∞—Ç–∞? –¢–ï–ö–°–¢: {text[:500]}
–û—Ç–≤–µ—Ç—å –¥–∞ –∏–ª–∏ –Ω–µ—Ç:"""

        check = await ai_client.chat(model, [
            {"role": "system", "content": "–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –¥–∞ –∏–ª–∏ –Ω–µ—Ç"},
            {"role": "user", "content": check_prompt}
        ], retries=2, max_tokens=10)
        
        check_response = check.get("content", "").lower().strip() if isinstance(check, dict) else str(check).lower().strip()
        
        if "–Ω–µ—Ç" in check_response or check_response == "no":
            return None
        
        normalize_prompt = f"""–ü—Ä–µ–æ–±—Ä–∞–∑—É–π –ø—Ä–∞–≤–∏–ª–∞ —á–∞—Ç–∞ –≤ —Å–ø–∏—Å–æ–∫ —Å –Ω–∞–∫–∞–∑–∞–Ω–∏—è–º–∏.

–ò–°–•–û–î–ù–´–ô –¢–ï–ö–°–¢:
{text[:1500]}

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
1. –ü—Ä–∞–≤–∏–ª–æ - –Ω–∞–∫–∞–∑–∞–Ω–∏–µ (–º—É—Ç/–±–∞–Ω/–≤–∞—Ä–Ω + –≤—Ä–µ–º—è –µ—Å–ª–∏ –µ—Å—Ç—å)
2. –ü—Ä–∞–≤–∏–ª–æ - –Ω–∞–∫–∞–∑–∞–Ω–∏–µ
–∏ —Ç.–¥.

–ü–†–ê–í–ò–õ–ê:
- –°–æ—Ö—Ä–∞–Ω—è–π —Å–º—ã—Å–ª, –Ω–æ –ø–∏—à–∏ –∫—Ä–∞—Ç–∫–æ
- –î–æ–ø—É—Å—Ç–∏–º—ã–µ –Ω–∞–∫–∞–∑–∞–Ω–∏—è: –º—É—Ç, –±–∞–Ω, –≤–∞—Ä–Ω (–º–æ–∂–Ω–æ —Å –≤—Ä–µ–º–µ–Ω–µ–º: –º—É—Ç 1—á, –º—É—Ç 10–º, –±–∞–Ω 1–¥)
- –ï—Å–ª–∏ –Ω–∞–∫–∞–∑–∞–Ω–∏–µ –Ω–µ —É–∫–∞–∑–∞–Ω–æ - –ø–∏—à–∏ "–º—É—Ç"
- –¢–æ–ª—å–∫–æ –ø—Ä–∞–≤–∏–ª–∞ —Å –Ω–∞—Ä—É—à–µ–Ω–∏—è–º–∏, –±–µ–∑ –æ–±—â–∏—Ö —Ñ—Ä–∞–∑

–û–¢–í–ï–¢:"""

        result = await ai_client.chat(model, [
            {"role": "system", "content": "–ü—Ä–µ–æ–±—Ä–∞–∑—É–π –ø—Ä–∞–≤–∏–ª–∞ –≤ —Å–ø–∏—Å–æ–∫. –§–æ—Ä–º–∞—Ç: 1. –ü—Ä–∞–≤–∏–ª–æ - –Ω–∞–∫–∞–∑–∞–Ω–∏–µ"},
            {"role": "user", "content": normalize_prompt}
        ], retries=3, max_tokens=500)
        
        response = result.get("content", "") if isinstance(result, dict) else str(result)
        
        if response and len(response) > 20 and not response.startswith("–û—à–∏–±–∫–∞"):
            return response[:2000]
        return text[:2000]
    except:
        return text[:2000] if len(text) > 50 else None


async def parse_staff_ai(ai_client, model: str, text: str) -> str:
    if not text or len(text) < 10:
        return None
    
    try:
        prompt = f"""–≠—Ç–æ —Å–ø–∏—Å–æ–∫ –∞–¥–º–∏–Ω–æ–≤/–º–æ–¥–µ—Ä–∞—Ç–æ—Ä–æ–≤ —á–∞—Ç–∞ –∏–ª–∏ —á—Ç–æ-—Ç–æ –¥—Ä—É–≥–æ–µ?

–¢–ï–ö–°–¢:
{text[:1000]}

–ï—Å–ª–∏ —ç—Ç–æ —Å–ø–∏—Å–æ–∫ —Å—Ç–∞—Ñ—Ñ–∞ (–∞–¥–º–∏–Ω—ã, –º–æ–¥–µ—Ä—ã, –≤–ª–∞–¥–µ–ª—å—Ü—ã —Å —é–∑–µ—Ä–Ω–µ–π–º–∞–º–∏) ‚Äî –æ—Ç–≤–µ—Ç—å "–¥–∞".
–ï—Å–ª–∏ —ç—Ç–æ –Ω–µ —Å–ø–∏—Å–æ–∫ —Å—Ç–∞—Ñ—Ñ–∞ ‚Äî –æ—Ç–≤–µ—Ç—å "–Ω–µ—Ç".
–û—Ç–≤–µ—Ç—å –û–î–ù–ò–ú —Å–ª–æ–≤–æ–º:"""

        result = await ai_client.chat(model, [
            {"role": "system", "content": "–û–ø—Ä–µ–¥–µ–ª–∏ —ç—Ç–æ —Å–ø–∏—Å–æ–∫ —Å—Ç–∞—Ñ—Ñ–∞ –∏–ª–∏ –Ω–µ—Ç. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ '–¥–∞' –∏–ª–∏ '–Ω–µ—Ç'."},
            {"role": "user", "content": prompt}
        ], retries=2, max_tokens=10)
        
        response = result.get("content", "").lower().strip() if isinstance(result, dict) else str(result).lower().strip()
        
        if "–¥–∞" in response or response == "yes":
            return text[:1000]
        return None
    except:
        return text[:1000] if "@" in text else None


def parse_rules_response(text: str) -> str:
    if not text or len(text) < 20:
        return None
    
    text_lower = text.lower()
    
    rule_indicators = [
        '–ø—Ä–∞–≤–∏–ª', '–∑–∞–ø—Ä–µ—â', '–Ω–µ–ª—å–∑—è', '—Ä–∞–∑—Ä–µ—à', '–º–æ–∂–Ω–æ', '–æ–±—è–∑–∞—Ç',
        'rules', 'rule', '–±–∞–Ω', '–º—É—Ç', '–≤–∞—Ä–Ω', 'kick', '–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥'
    ]
    
    if not any(ind in text_lower for ind in rule_indicators):
        return None
    
    return text[:2000]


def parse_staff_response(text: str) -> str:
    if not text or len(text) < 10:
        return None
    
    text_lower = text.lower()
    
    staff_indicators = [
        '–≤–ª–∞–¥–µ–ª', '–∞–¥–º–∏–Ω', '–º–æ–¥–µ—Ä', 'owner', 'admin', 'staff',
        '—Å–æ–∑–¥–∞—Ç–µ–ª', '–æ—Å–Ω–æ–≤–∞—Ç–µ–ª', '–≥–ª–∞–≤', '@'
    ]
    
    if not any(ind in text_lower for ind in staff_indicators):
        return None
    
    return text[:1000]


async def wait_for_bot_response(client, chat_id: int, trigger_msg_id: int, timeout: int = 70) -> str:
    end_time = asyncio.get_event_loop().time() + timeout
    last_checked_id = trigger_msg_id
    
    while asyncio.get_event_loop().time() < end_time:
        await asyncio.sleep(3)
        
        try:
            messages = await client.get_messages(chat_id, limit=10, min_id=last_checked_id)
            
            for msg in messages:
                if msg.id <= trigger_msg_id:
                    continue
                    
                if msg.sender_id and msg.sender_id != (await client.get_me()).id:
                    sender = await msg.get_sender()
                    if sender and getattr(sender, 'bot', False):
                        return msg.message
                
                last_checked_id = max(last_checked_id, msg.id)
                
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞: {e}")
            break
    
    return None


def get_join_greeting() -> str:
    greetings = [
        "–ø—Ä–∏–≤ –≤—Å–µ–º",
        "—Ö–µ–π",
        "–ø—Ä–∏–≤–µ—Ç",
        "–∑–¥–∞—Ä–æ–≤",
        "–ø—Ä–∏–≤–µ—Ç–∏–∫–∏",
        "–æ, –ø—Ä–∏–≤–µ—Ç –≤—Å–µ–º",
    ]
    return random.choice(greetings)

